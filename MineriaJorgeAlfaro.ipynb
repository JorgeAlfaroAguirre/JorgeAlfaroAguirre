{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoVUvy+l6xI1g5TikSjGaC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgeAlfaroAguirre/JorgeAlfaroAguirre/blob/main/MineriaJorgeAlfaro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio pandas numpy matplotlib seaborn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoqS9t8JFgtW",
        "outputId": "f1c5fbd8-6ee0-4d2d-866c-d37d583e00a2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.5.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.19)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import seaborn as sns\n",
        "\n",
        "# Variable global para almacenar el DataFrame cargado\n",
        "dataframe = None\n",
        "\n",
        "# --- Cargar archivo ---\n",
        "def process_file(file):\n",
        "    global dataframe\n",
        "    if file.name.endswith('.csv'):\n",
        "        dataframe = pd.read_csv(file.name)\n",
        "    elif file.name.endswith(('.xls', '.xlsx')):\n",
        "        dataframe = pd.read_excel(file.name)\n",
        "    else:\n",
        "        return \"Error: Solo se aceptan archivos CSV o Excel.\", None\n",
        "\n",
        "    headers = dataframe.columns.tolist()\n",
        "\n",
        "    numeric_headers = [col for col in headers if pd.api.types.is_numeric_dtype(dataframe[col])]\n",
        "    categorical_headers = [col for col in headers if not pd.api.types.is_numeric_dtype(dataframe[col])]\n",
        "\n",
        "    total_rows = len(dataframe)\n",
        "    summary = (\n",
        "        f\"Archivo cargado correctamente.\\n\\n\"\n",
        "        f\"Headers numéricos:\\n\" + \"\\n\".join(numeric_headers) + \"\\n\\n\"\n",
        "        f\"Headers categóricos:\\n\" + \"\\n\".join(categorical_headers) + \"\\n\\n\"\n",
        "        f\"Número total de filas: {total_rows}\"\n",
        "    )\n",
        "    return summary, dataframe.head(100)\n",
        "\n",
        "# --- Limpieza de valores mixtos ---\n",
        "def remove_mixed_data():\n",
        "    global dataframe\n",
        "    if dataframe is None:\n",
        "        return \"No hay un archivo cargado para limpiar.\", None, None\n",
        "\n",
        "    original_rows = len(dataframe)\n",
        "    rows_to_drop = set()\n",
        "\n",
        "    for column in dataframe.columns:\n",
        "        valid_values = dataframe[column].dropna().apply(lambda x: x if len(str(x).strip()) > 0 else None).dropna()\n",
        "        unique_types = valid_values.apply(type).unique()\n",
        "\n",
        "        if len(unique_types) > 1:\n",
        "            numeric_count = valid_values.apply(lambda x: isinstance(x, (int, float))).sum()\n",
        "            categorical_count = valid_values.apply(lambda x: isinstance(x, str)).sum()\n",
        "\n",
        "            if numeric_count >= categorical_count:\n",
        "                dataframe[column] = dataframe[column].apply(\n",
        "                    lambda x: pd.to_numeric(x, errors='coerce') if isinstance(x, (int, float, str)) else x\n",
        "                )\n",
        "            else:\n",
        "                dataframe[column] = dataframe[column].apply(\n",
        "                    lambda x: x if isinstance(x, str) else None\n",
        "                )\n",
        "\n",
        "            rows_to_drop.update(dataframe[dataframe[column].notnull() & dataframe[column].isnull()].index)\n",
        "\n",
        "    dataframe.drop(index=rows_to_drop, inplace=True)\n",
        "    affected_rows = len(rows_to_drop)\n",
        "\n",
        "    numeric_headers = [col for col in dataframe.columns if pd.api.types.is_numeric_dtype(dataframe[col])]\n",
        "    categorical_headers = [col for col in dataframe.columns if not pd.api.types.is_numeric_dtype(dataframe[col])]\n",
        "    summary = (\n",
        "        f\"Headers actualizados después de limpiar valores mixtos:\\n\\n\"\n",
        "        f\"Headers numéricos:\\n\" + \"\\n\".join(numeric_headers) + \"\\n\\n\"\n",
        "        f\"Headers categóricos:\\n\" + \"\\n\".join(categorical_headers) + \"\\n\\n\"\n",
        "        f\"Número total de filas: {len(dataframe)}\"\n",
        "    )\n",
        "\n",
        "    return f\"Se eliminaron {affected_rows} filas con valores mixtos.\", summary, dataframe.head(100)\n",
        "\n",
        "# --- Limpieza de valores nulos ---\n",
        "def handle_nulls(option):\n",
        "    global dataframe\n",
        "    if dataframe is None:\n",
        "        return \"No hay un archivo cargado para limpiar.\", None\n",
        "\n",
        "    affected_rows = dataframe.isnull().any(axis=1).sum()\n",
        "    if option == \"Dejar los nulos o vacíos con valor 0\":\n",
        "        dataframe.fillna(0, inplace=True)\n",
        "        modification = \"Valores nulos reemplazados por 0.\"\n",
        "    elif option == \"Borrar la fila completa\":\n",
        "        dataframe.dropna(inplace=True)\n",
        "        modification = \"Filas con valores nulos eliminadas.\"\n",
        "    elif option == \"Colocar el promedio\":\n",
        "        for column in dataframe.columns:\n",
        "            if dataframe[column].isnull().any() and pd.api.types.is_numeric_dtype(dataframe[column]):\n",
        "                mean_value = dataframe[column].mean()\n",
        "                dataframe[column].fillna(mean_value, inplace=True)\n",
        "        modification = \"Valores nulos reemplazados por el promedio.\"\n",
        "    elif option == \"Colocar la mediana\":\n",
        "        for column in dataframe.columns:\n",
        "            if dataframe[column].isnull().any() and pd.api.types.is_numeric_dtype(dataframe[column]):\n",
        "                median_value = dataframe[column].median()\n",
        "                dataframe[column].fillna(median_value, inplace=True)\n",
        "        modification = \"Valores nulos reemplazados por la mediana.\"\n",
        "    else:\n",
        "        return \"Opción no válida.\", None\n",
        "\n",
        "    return f\"{modification}\\nRegistros afectados: {affected_rows}\", dataframe.head(100)\n",
        "\n",
        "# --- Normalización y estandarización ---\n",
        "def normalize_or_standardize(column, method):\n",
        "    global dataframe\n",
        "    if dataframe is None:\n",
        "        return \"No hay un archivo cargado para analizar.\", None\n",
        "\n",
        "    if column not in dataframe.columns or not pd.api.types.is_numeric_dtype(dataframe[column]):\n",
        "        return \"Alerta: Debes seleccionar una columna numérica.\", None\n",
        "\n",
        "    if method == \"Min-Max\":\n",
        "        min_val = dataframe[column].min()\n",
        "        max_val = dataframe[column].max()\n",
        "        dataframe[column] = (dataframe[column] - min_val) / (max_val - min_val)\n",
        "        result = f\"Normalización Min-Max realizada en la columna {column}.\"\n",
        "    elif method == \"Z-Score\":\n",
        "        mean = dataframe[column].mean()\n",
        "        std_dev = dataframe[column].std()\n",
        "        dataframe[column] = (dataframe[column] - mean) / std_dev\n",
        "        result = f\"Estandarización Z-Score realizada en la columna {column}.\"\n",
        "    else:\n",
        "        return \"Método no válido.\", None\n",
        "\n",
        "    return result, dataframe.head(100)\n",
        "\n",
        "# --- Análisis estadístico ---\n",
        "def analyze_statistics(columns):\n",
        "    \"\"\"Realiza un análisis estadístico básico en las columnas seleccionadas.\"\"\"\n",
        "    global dataframe\n",
        "    if dataframe is None:\n",
        "        return \"Error: No hay un archivo cargado para analizar.\"\n",
        "\n",
        "    # Dividir las columnas por comas y quitar espacios en blanco\n",
        "    selected_columns = [col.strip() for col in columns.split(\",\")]\n",
        "\n",
        "    # Verificar si las columnas existen y son numéricas\n",
        "    invalid_columns = [col for col in selected_columns if col not in dataframe.columns or not pd.api.types.is_numeric_dtype(dataframe[col])]\n",
        "    if invalid_columns:\n",
        "        return f\"Error: Las siguientes columnas no son válidas o no son numéricas: {', '.join(invalid_columns)}\"\n",
        "\n",
        "    try:\n",
        "        # Correlaciones entre las columnas seleccionadas\n",
        "        correlation_matrix = dataframe[selected_columns].corr().to_string()\n",
        "\n",
        "        # Curtosis para cada columna seleccionada\n",
        "        kurtosis_values = dataframe[selected_columns].kurt().to_dict()\n",
        "\n",
        "        # Simetría (Skewness) para cada columna seleccionada\n",
        "        skewness_values = dataframe[selected_columns].skew().to_dict()\n",
        "\n",
        "        # Outliers (IQR) para cada columna seleccionada\n",
        "        outlier_info = {}\n",
        "        for col in selected_columns:\n",
        "            Q1 = dataframe[col].quantile(0.25)\n",
        "            Q3 = dataframe[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            outliers = dataframe[(dataframe[col] < lower_bound) | (dataframe[col] > upper_bound)][col]\n",
        "            outlier_info[col] = {\n",
        "                \"Número de outliers\": len(outliers),\n",
        "                \"Valores\": outliers.tolist()\n",
        "            }\n",
        "\n",
        "        # Generar resultados\n",
        "        result = \"--- Análisis Estadístico ---\\n\"\n",
        "        result += \"--- Correlaciones ---\\n\" + correlation_matrix + \"\\n\\n\"\n",
        "        result += \"--- Curtosis ---\\n\" + \"\\n\".join([f\"{col}: {round(val, 2)}\" for col, val in kurtosis_values.items()]) + \"\\n\\n\"\n",
        "        result += \"--- Simetría ---\\n\" + \"\\n\".join([f\"{col}: {round(val, 2)}\" for col, val in skewness_values.items()]) + \"\\n\\n\"\n",
        "        result += \"--- Outliers (IQR) ---\\n\"\n",
        "        for col, info in outlier_info.items():\n",
        "            result += f\"Columna: {col}\\nNúmero de outliers: {info['Número de outliers']}\\nValores: {info['Valores']}\\n\\n\"\n",
        "\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"Error durante el análisis estadístico: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "Tix3XHaDboV6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "\n",
        "# --- Graficos y Conclusiones ---\n",
        "def generate_graphs_and_conclusions(columns):\n",
        "    \"\"\"Genera gráficos y un informe basado en columnas seleccionadas.\"\"\"\n",
        "    global dataframe\n",
        "    if dataframe is None:\n",
        "        return \"Error: No hay un archivo cargado.\", None, None, None\n",
        "\n",
        "    # Validar selección de columnas\n",
        "    selected_columns = [col.strip() for col in columns.split(\",\")]\n",
        "    invalid_columns = [col for col in selected_columns if col not in dataframe.columns]\n",
        "    if invalid_columns:\n",
        "        return f\"Error: Las siguientes columnas no existen: {', '.join(invalid_columns)}\", None, None, None\n",
        "\n",
        "    if len(selected_columns) < 2:\n",
        "        return \"Error: Se necesitan al menos 2 columnas para algunos gráficos (e.g., mapa de correlación).\", None, None, None\n",
        "\n",
        "    try:\n",
        "        outputs = []\n",
        "\n",
        "        # --- Gráfico Boxplot ---\n",
        "        try:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            dataframe[selected_columns].boxplot()\n",
        "            plt.title(\"Boxplot de Outliers\")\n",
        "            boxplot_buffer = BytesIO()\n",
        "            plt.savefig(boxplot_buffer, format=\"png\")\n",
        "            plt.close()\n",
        "            boxplot_buffer.seek(0)\n",
        "            outputs.append(boxplot_buffer)\n",
        "        except Exception as e:\n",
        "            return f\"Error en Boxplot: {str(e)}\", None, None, None\n",
        "\n",
        "        # --- Mapa de Correlaciones ---\n",
        "        try:\n",
        "            corr_matrix = dataframe[selected_columns].corr()\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "            plt.title(\"Mapa de Correlaciones\")\n",
        "            correlation_buffer = BytesIO()\n",
        "            plt.savefig(correlation_buffer, format=\"png\")\n",
        "            plt.close()\n",
        "            correlation_buffer.seek(0)\n",
        "            outputs.append(correlation_buffer)\n",
        "        except Exception as e:\n",
        "            return f\"Error en Mapa de Correlaciones: {str(e)}\", None, None, None\n",
        "\n",
        "        # --- Histograma ---\n",
        "        try:\n",
        "            hist_buffers = []\n",
        "            for col in selected_columns:\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                sns.histplot(dataframe[col].dropna(), bins=20, kde=False, color='skyblue')\n",
        "                plt.title(f\"Histograma de {col}\")\n",
        "                plt.xlabel('Valores')\n",
        "                plt.ylabel('Frecuencia')\n",
        "                hist_buffer = BytesIO()\n",
        "                plt.savefig(hist_buffer, format=\"png\")\n",
        "                plt.close()\n",
        "                hist_buffer.seek(0)\n",
        "                hist_buffers.append(hist_buffer)\n",
        "            outputs.append(hist_buffers)\n",
        "        except Exception as e:\n",
        "            return f\"Error en Histograma: {str(e)}\", None, None, None\n",
        "\n",
        "        return \"Gráficos generados correctamente.\", outputs[0], outputs[1], outputs[2]\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error al generar gráficos: {str(e)}\", None, None, None\n",
        "\n",
        "\n",
        "# --- Generación de Informes ---\n",
        "def generar_log(dataframe, log_filename=\"informe_log.txt\"):\n",
        "    \"\"\"Genera un informe de las decisiones tomadas y un resumen estadístico.\"\"\"\n",
        "    try:\n",
        "        with open(log_filename, 'w') as log_file:\n",
        "            log_file.write(f\"Análisis realizado el: {pd.Timestamp.now()}\\n\\n\")\n",
        "            log_file.write(\"Decisiones tomadas:\\n\")\n",
        "            log_file.write(\"- Se eliminaron valores nulos (método: promedio)\\n\")\n",
        "            log_file.write(\"- Se utilizó la normalización Min-Max en las columnas seleccionadas\\n\\n\")\n",
        "            log_file.write(\"Resumen Estadístico:\\n\")\n",
        "            log_file.write(dataframe.describe().to_string())\n",
        "        return f\"Informe generado con éxito: {log_filename}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error al generar el informe: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "lFjl6OZrvmak"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# --- Interfaz de usuario ---\n",
        "with gr.Blocks() as interface:\n",
        "    gr.Markdown(\"## Aplicación Interactiva para Procesamiento y Análisis de Datos\")\n",
        "    gr.Markdown(\n",
        "        \"### Desarrollado por Jorge Alfaro\\n\"\n",
        "        \"Esta herramienta fue creada para facilitar el procesamiento y análisis de datos de forma interactiva, \"\n",
        "        \"integrando técnicas de limpieza, transformación y análisis estadístico.\"\n",
        "    )\n",
        "\n",
        "    # Carga de archivo\n",
        "    gr.Markdown(\n",
        "        \"### Carga de archivo\\n\"\n",
        "        \"Permite cargar un archivo en formato CSV o Excel para su análisis. \"\n",
        "        \"El sistema genera un resumen indicando las columnas numéricas, categóricas y el número de filas totales.\"\n",
        "    )\n",
        "    file_input = gr.File(label=\"Cargar archivo\")\n",
        "    summary_output = gr.Textbox(label=\"Resumen de headers (Numéricos y Categóricos)\")\n",
        "    table_output = gr.DataFrame(label=\"Vista previa (hasta 100 filas)\")\n",
        "    file_input.change(process_file, inputs=[file_input], outputs=[summary_output, table_output])\n",
        "\n",
        "    # Limpieza de valores mixtos\n",
        "    gr.Markdown(\n",
        "        \"### Limpieza de Valores Mixtos\\n\"\n",
        "        \"Los valores mixtos se producen cuando una columna numérica contiene datos no numéricos, dificultando el análisis. \"\n",
        "        \"Esta función elimina esos valores no numéricos para normalizar los datos.\"\n",
        "    )\n",
        "    remove_mixed_button = gr.Button(\"Eliminar valores mixtos\")\n",
        "    remove_mixed_result = gr.Textbox(label=\"Resultado de limpieza de valores mixtos\")\n",
        "    updated_summary_output = gr.Textbox(label=\"Resumen actualizado de headers\")\n",
        "    updated_table_output = gr.DataFrame(label=\"Datos después de limpiar valores mixtos\")\n",
        "    remove_mixed_button.click(\n",
        "        remove_mixed_data,\n",
        "        outputs=[remove_mixed_result, updated_summary_output, updated_table_output]\n",
        "    )\n",
        "\n",
        "    # Limpieza de datos nulos\n",
        "    gr.Markdown(\n",
        "        \"### Limpieza de Valores Nulos\\n\"\n",
        "        \"Los valores nulos son datos faltantes en las columnas. \"\n",
        "        \"Esta función permite elegir entre reemplazarlos con 0, la media, la mediana, o eliminar las filas completas.\"\n",
        "    )\n",
        "    null_handling_options = gr.Dropdown(\n",
        "        choices=[\"Dejar los nulos o vacíos con valor 0\", \"Borrar la fila completa\", \"Colocar el promedio\", \"Colocar la mediana\"],\n",
        "        label=\"Selecciona una acción para los valores nulos\"\n",
        "    )\n",
        "    clean_button = gr.Button(\"Aplicar limpieza\")\n",
        "    clean_result = gr.Textbox(label=\"Resultado de limpieza\")\n",
        "    clean_table = gr.DataFrame(label=\"Datos después de la limpieza\")\n",
        "    clean_button.click(handle_nulls, inputs=[null_handling_options], outputs=[clean_result, clean_table])\n",
        "\n",
        "    # Selección de headers y transformación\n",
        "    gr.Markdown(\n",
        "        \"### Selección de Headers y Transformaciones\\n\"\n",
        "        \"Permite seleccionar una columna numérica para realizar transformaciones como normalización (Min-Max) o estandarización (Z-Score).\"\n",
        "    )\n",
        "    header_selector = gr.Textbox(label=\"Escribe el nombre del header (columna numérica)\", interactive=True)\n",
        "\n",
        "    # Normalización y estandarización\n",
        "    gr.Markdown(\n",
        "        \"### Normalización y Estandarización\\n\"\n",
        "        \"#### Normalización (Min-Max):\\n\"\n",
        "        \"- Escala los valores entre 0 y 1.\\n\"\n",
        "        \"- Fórmula: `(valor - mínimo) / (máximo - mínimo)`.\\n\"\n",
        "        \"- Útil para garantizar que todos los valores estén en un rango fijo, evitando que un rango más grande domine otros.\\n\\n\"\n",
        "        \"#### Estandarización (Z-Score):\\n\"\n",
        "        \"- Ajusta los valores para que tengan una media de 0 y una desviación estándar de 1.\\n\"\n",
        "        \"- Fórmula: `(valor - media) / desviación estándar`.\\n\"\n",
        "        \"- Z-Scores mayores a 1 o menores a -1 indican valores alejados de la media (potenciales outliers).\"\n",
        "    )\n",
        "    method_selector = gr.Dropdown(choices=[\"Min-Max\", \"Z-Score\"], label=\"Selecciona el método de transformación\")\n",
        "    normalize_button = gr.Button(\"Aplicar transformación\")\n",
        "    normalize_result = gr.Textbox(label=\"Resultado de la transformación\")\n",
        "    normalize_table = gr.DataFrame(label=\"Datos después de transformación\")\n",
        "    normalize_button.click(\n",
        "        normalize_or_standardize,\n",
        "        inputs=[header_selector, method_selector],\n",
        "        outputs=[normalize_result, normalize_table]\n",
        "    )\n",
        "\n",
        "    # Campo para seleccionar columnas para el análisis estadístico\n",
        "    gr.Markdown(\n",
        "        \"### Selección de columnas para Análisis Estadístico\\n\"\n",
        "        \"Permite especificar las columnas numéricas sobre las que se realizará el análisis estadístico, separadas por comas.\"\n",
        "    )\n",
        "    analysis_columns_selector = gr.Textbox(label=\"Escribe los nombres de las columnas separadas por comas\", interactive=True)\n",
        "\n",
        "    # Análisis Estadístico\n",
        "    gr.Markdown(\n",
        "        \"### Análisis Estadístico\\n\"\n",
        "        \"#### Correlación:\\n\"\n",
        "        \"- Mide la relación entre dos variables numéricas.\\n\"\n",
        "        \"- Valores entre -1 y 1:\\n\"\n",
        "        \"  - **1**: Correlación positiva perfecta (ambas aumentan juntas).\\n\"\n",
        "        \"  - **-1**: Correlación negativa perfecta (una aumenta, la otra disminuye).\\n\"\n",
        "        \"  - **0**: Sin correlación.\\n\\n\"\n",
        "        \"#### Curtosis:\\n\"\n",
        "        \"- Indica la forma de las colas de una distribución en comparación con una distribución normal.\\n\"\n",
        "        \"- **Curtosis alta (>3):** Colas más pesadas (leptocúrtica).\\n\"\n",
        "        \"- **Curtosis baja (<3):** Colas más ligeras (platicúrtica).\\n\"\n",
        "        \"- **Curtosis ≈ 3:** Distribución normal (mesocúrtica).\\n\\n\"\n",
        "        \"#### Simetría (Skewness):\\n\"\n",
        "        \"- Indica la asimetría de una distribución.\\n\"\n",
        "        \"- **Skewness positiva:** Más valores pequeños, cola a la derecha.\\n\"\n",
        "        \"- **Skewness negativa:** Más valores grandes, cola a la izquierda.\\n\"\n",
        "        \"- **Skewness ≈ 0:** Distribución simétrica.\\n\\n\"\n",
        "        \"#### Outliers:\\n\"\n",
        "        \"- Valores extremos que se alejan significativamente del rango típico.\\n\"\n",
        "        \"- Detectados usando el Rango Intercuartil (IQR):\\n\"\n",
        "        \"  - **Límite inferior:** Q1 - 1.5 * IQR\\n\"\n",
        "        \"  - **Límite superior:** Q3 + 1.5 * IQR\\n\"\n",
        "        \"  - Valores fuera de estos límites son outliers.\"\n",
        "    )\n",
        "    analyze_button = gr.Button(\"Realizar Análisis Estadístico\")\n",
        "    analysis_result = gr.Textbox(label=\"Resultados del Análisis Estadístico\")\n",
        "    analyze_button.click(\n",
        "        analyze_statistics,\n",
        "        inputs=[analysis_columns_selector],\n",
        "        outputs=[analysis_result]\n",
        "    )\n",
        "\n",
        "    # Generar Gráficos y Conclusiones\n",
        "    gr.Markdown(\n",
        "        \"### Generar Gráficos y Conclusiones\\n\"\n",
        "        \"Permite generar gráficos (boxplot, mapa de correlaciones, histograma) basados en las columnas seleccionadas. \"\n",
        "        \"También genera un informe automático con las decisiones tomadas y un resumen estadístico.\"\n",
        "    )\n",
        "    column_selector = gr.Textbox(label=\"Escribe los nombres de las columnas separadas por comas\", interactive=True)\n",
        "    generate_graphs_button = gr.Button(\"Generar Gráficos y Conclusiones\")\n",
        "    graphs_boxplot = gr.Image(label=\"Boxplot de Outliers\")\n",
        "    graphs_correlation = gr.Image(label=\"Mapa de Correlaciones\")\n",
        "    graphs_histograms = gr.Gallery(label=\"Histogramas\")\n",
        "    conclusions_output = gr.Textbox(label=\"Conclusiones Generales\")\n",
        "    generate_graphs_button.click(\n",
        "        generate_graphs_and_conclusions,\n",
        "        inputs=[column_selector],\n",
        "        outputs=[conclusions_output, graphs_boxplot, graphs_correlation, graphs_histograms]\n",
        "    )\n",
        "\n",
        "    # Generar Informe\n",
        "    gr.Markdown(\n",
        "        \"### Generación de Informes\\n\"\n",
        "        \"Genera un archivo de texto con un resumen de las decisiones tomadas y un análisis estadístico de los datos cargados.\"\n",
        "    )\n",
        "    generate_log_button = gr.Button(\"Generar Informe\")\n",
        "    log_result = gr.Textbox(label=\"Resultado de la generación del informe\")\n",
        "    generate_log_button.click(\n",
        "        lambda: generar_log(dataframe, \"informe_log.txt\"),\n",
        "        outputs=log_result\n",
        "    )\n",
        "\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "Sps85ngC6IYJ",
        "outputId": "f8a86bce-14e8-468d-8c79-c799f57aa03d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://dd9823f4f2cf98b6cd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dd9823f4f2cf98b6cd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}