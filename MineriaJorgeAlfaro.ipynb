{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1f0asVw+TX2xGfCM5uXGr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgeAlfaroAguirre/JorgeAlfaroAguirre/blob/main/MineriaJorgeAlfaro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio pandas numpy matplotlib seaborn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoqS9t8JFgtW",
        "outputId": "f1c5fbd8-6ee0-4d2d-866c-d37d583e00a2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.5.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.19)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import seaborn as sns\n",
        "\n",
        "# Variable global para almacenar el DataFrame cargado\n",
        "dataframe = None\n",
        "\n",
        "# --- Cargar archivo ---\n",
        "def process_file(file):\n",
        "    global dataframe\n",
        "    if file.name.endswith('.csv'):\n",
        "        dataframe = pd.read_csv(file.name)\n",
        "    elif file.name.endswith(('.xls', '.xlsx')):\n",
        "        dataframe = pd.read_excel(file.name)\n",
        "    else:\n",
        "        return \"Error: Solo se aceptan archivos CSV o Excel.\", None\n",
        "\n",
        "    headers = dataframe.columns.tolist()\n",
        "\n",
        "    numeric_headers = [col for col in headers if pd.api.types.is_numeric_dtype(dataframe[col])]\n",
        "    categorical_headers = [col for col in headers if not pd.api.types.is_numeric_dtype(dataframe[col])]\n",
        "\n",
        "    total_rows = len(dataframe)\n",
        "    summary = (\n",
        "        f\"Archivo cargado correctamente.\\n\\n\"\n",
        "        f\"Headers numéricos:\\n\" + \"\\n\".join(numeric_headers) + \"\\n\\n\"\n",
        "        f\"Headers categóricos:\\n\" + \"\\n\".join(categorical_headers) + \"\\n\\n\"\n",
        "        f\"Número total de filas: {total_rows}\"\n",
        "    )\n",
        "    return summary, dataframe.head(100)\n",
        "\n",
        "# --- Limpieza de valores mixtos ---\n",
        "def remove_mixed_data():\n",
        "    global dataframe\n",
        "    if dataframe is None:\n",
        "        return \"No hay un archivo cargado para limpiar.\", None, None\n",
        "\n",
        "    original_rows = len(dataframe)\n",
        "    rows_to_drop = set()\n",
        "\n",
        "    for column in dataframe.columns:\n",
        "        valid_values = dataframe[column].dropna().apply(lambda x: x if len(str(x).strip()) > 0 else None).dropna()\n",
        "        unique_types = valid_values.apply(type).unique()\n",
        "\n",
        "        if len(unique_types) > 1:\n",
        "            numeric_count = valid_values.apply(lambda x: isinstance(x, (int, float))).sum()\n",
        "            categorical_count = valid_values.apply(lambda x: isinstance(x, str)).sum()\n",
        "\n",
        "            if numeric_count >= categorical_count:\n",
        "                dataframe[column] = dataframe[column].apply(\n",
        "                    lambda x: pd.to_numeric(x, errors='coerce') if isinstance(x, (int, float, str)) else x\n",
        "                )\n",
        "            else:\n",
        "                dataframe[column] = dataframe[column].apply(\n",
        "                    lambda x: x if isinstance(x, str) else None\n",
        "                )\n",
        "\n",
        "            rows_to_drop.update(dataframe[dataframe[column].notnull() & dataframe[column].isnull()].index)\n",
        "\n",
        "    dataframe.drop(index=rows_to_drop, inplace=True)\n",
        "    affected_rows = len(rows_to_drop)\n",
        "\n",
        "    numeric_headers = [col for col in dataframe.columns if pd.api.types.is_numeric_dtype(dataframe[col])]\n",
        "    categorical_headers = [col for col in dataframe.columns if not pd.api.types.is_numeric_dtype(dataframe[col])]\n",
        "    summary = (\n",
        "        f\"Headers actualizados después de limpiar valores mixtos:\\n\\n\"\n",
        "        f\"Headers numéricos:\\n\" + \"\\n\".join(numeric_headers) + \"\\n\\n\"\n",
        "        f\"Headers categóricos:\\n\" + \"\\n\".join(categorical_headers) + \"\\n\\n\"\n",
        "        f\"Número total de filas: {len(dataframe)}\"\n",
        "    )\n",
        "\n",
        "    return f\"Se eliminaron {affected_rows} filas con valores mixtos.\", summary, dataframe.head(100)\n",
        "\n",
        "# --- Limpieza de valores nulos ---\n",
        "def handle_nulls(option):\n",
        "    global dataframe\n",
        "    if dataframe is None:\n",
        "        return \"No hay un archivo cargado para limpiar.\", None\n",
        "\n",
        "    affected_rows = dataframe.isnull().any(axis=1).sum()\n",
        "    if option == \"Dejar los nulos o vacíos con valor 0\":\n",
        "        dataframe.fillna(0, inplace=True)\n",
        "        modification = \"Valores nulos reemplazados por 0.\"\n",
        "    elif option == \"Borrar la fila completa\":\n",
        "        dataframe.dropna(inplace=True)\n",
        "        modification = \"Filas con valores nulos eliminadas.\"\n",
        "    elif option == \"Colocar el promedio\":\n",
        "        for column in dataframe.columns:\n",
        "            if dataframe[column].isnull().any() and pd.api.types.is_numeric_dtype(dataframe[column]):\n",
        "                mean_value = dataframe[column].mean()\n",
        "                dataframe[column].fillna(mean_value, inplace=True)\n",
        "        modification = \"Valores nulos reemplazados por el promedio.\"\n",
        "    elif option == \"Colocar la mediana\":\n",
        "        for column in dataframe.columns:\n",
        "            if dataframe[column].isnull().any() and pd.api.types.is_numeric_dtype(dataframe[column]):\n",
        "                median_value = dataframe[column].median()\n",
        "                dataframe[column].fillna(median_value, inplace=True)\n",
        "        modification = \"Valores nulos reemplazados por la mediana.\"\n",
        "    else:\n",
        "        return \"Opción no válida.\", None\n",
        "\n",
        "    return f\"{modification}\\nRegistros afectados: {affected_rows}\", dataframe.head(100)\n",
        "\n",
        "# --- Normalización y estandarización ---\n",
        "def normalize_or_standardize(column, method):\n",
        "    global dataframe\n",
        "    if dataframe is None:\n",
        "        return \"No hay un archivo cargado para analizar.\", None\n",
        "\n",
        "    if column not in dataframe.columns or not pd.api.types.is_numeric_dtype(dataframe[column]):\n",
        "        return \"Alerta: Debes seleccionar una columna numérica.\", None\n",
        "\n",
        "    if method == \"Min-Max\":\n",
        "        min_val = dataframe[column].min()\n",
        "        max_val = dataframe[column].max()\n",
        "        dataframe[column] = (dataframe[column] - min_val) / (max_val - min_val)\n",
        "        result = f\"Normalización Min-Max realizada en la columna {column}.\"\n",
        "    elif method == \"Z-Score\":\n",
        "        mean = dataframe[column].mean()\n",
        "        std_dev = dataframe[column].std()\n",
        "        dataframe[column] = (dataframe[column] - mean) / std_dev\n",
        "        result = f\"Estandarización Z-Score realizada en la columna {column}.\"\n",
        "    else:\n",
        "        return \"Método no válido.\", None\n",
        "\n",
        "    return result, dataframe.head(100)\n",
        "\n",
        "# --- Análisis estadístico ---\n",
        "def analyze_statistics(columns):\n",
        "    \"\"\"Realiza un análisis estadístico básico en las columnas seleccionadas.\"\"\"\n",
        "    global dataframe\n",
        "    if dataframe is None:\n",
        "        return \"Error: No hay un archivo cargado para analizar.\"\n",
        "\n",
        "    # Dividir las columnas por comas y quitar espacios en blanco\n",
        "    selected_columns = [col.strip() for col in columns.split(\",\")]\n",
        "\n",
        "    # Verificar si las columnas existen y son numéricas\n",
        "    invalid_columns = [col for col in selected_columns if col not in dataframe.columns or not pd.api.types.is_numeric_dtype(dataframe[col])]\n",
        "    if invalid_columns:\n",
        "        return f\"Error: Las siguientes columnas no son válidas o no son numéricas: {', '.join(invalid_columns)}\"\n",
        "\n",
        "    try:\n",
        "        # Correlaciones entre las columnas seleccionadas\n",
        "        correlation_matrix = dataframe[selected_columns].corr().to_string()\n",
        "\n",
        "        # Curtosis para cada columna seleccionada\n",
        "        kurtosis_values = dataframe[selected_columns].kurt().to_dict()\n",
        "\n",
        "        # Simetría (Skewness) para cada columna seleccionada\n",
        "        skewness_values = dataframe[selected_columns].skew().to_dict()\n",
        "\n",
        "        # Outliers (IQR) para cada columna seleccionada\n",
        "        outlier_info = {}\n",
        "        for col in selected_columns:\n",
        "            Q1 = dataframe[col].quantile(0.25)\n",
        "            Q3 = dataframe[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            outliers = dataframe[(dataframe[col] < lower_bound) | (dataframe[col] > upper_bound)][col]\n",
        "            outlier_info[col] = {\n",
        "                \"Número de outliers\": len(outliers),\n",
        "                \"Valores\": outliers.tolist()\n",
        "            }\n",
        "\n",
        "        # Generar resultados\n",
        "        result = \"--- Análisis Estadístico ---\\n\"\n",
        "        result += \"--- Correlaciones ---\\n\" + correlation_matrix + \"\\n\\n\"\n",
        "        result += \"--- Curtosis ---\\n\" + \"\\n\".join([f\"{col}: {round(val, 2)}\" for col, val in kurtosis_values.items()]) + \"\\n\\n\"\n",
        "        result += \"--- Simetría ---\\n\" + \"\\n\".join([f\"{col}: {round(val, 2)}\" for col, val in skewness_values.items()]) + \"\\n\\n\"\n",
        "        result += \"--- Outliers (IQR) ---\\n\"\n",
        "        for col, info in outlier_info.items():\n",
        "            result += f\"Columna: {col}\\nNúmero de outliers: {info['Número de outliers']}\\nValores: {info['Valores']}\\n\\n\"\n",
        "\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"Error durante el análisis estadístico: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "Tix3XHaDboV6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import seaborn as sns\n",
        "\n",
        "# Variable global para almacenar el DataFrame cargado\n",
        "dataframe = None\n",
        "\n",
        "# --- Graficos y Conclusiones ---\n",
        "def generate_graphs_and_conclusions(column_inputs):\n",
        "    \"\"\"Genera gráficos y un informe basado en columnas seleccionadas.\"\"\"\n",
        "    global dataframe\n",
        "    if dataframe is None:\n",
        "        return \"Error: No hay un archivo cargado.\", None, None, None, None, None\n",
        "\n",
        "    selected_columns = {key: [col.strip() for col in cols.split(\",\") if col.strip()] for key, cols in column_inputs.items()}\n",
        "    outputs = {\n",
        "        \"boxplot\": None,\n",
        "        \"heatmap\": None,\n",
        "        \"histograms\": [],\n",
        "        \"density\": [],\n",
        "        \"conclusions\": []\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        conclusions = []\n",
        "\n",
        "        # --- Boxplot ---\n",
        "        if \"boxplot\" in selected_columns and selected_columns[\"boxplot\"]:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            dataframe[selected_columns[\"boxplot\"]].boxplot()\n",
        "            plt.title(\"Boxplot de Outliers\")\n",
        "            boxplot_buffer = BytesIO()\n",
        "            plt.savefig(boxplot_buffer, format=\"png\")\n",
        "            plt.close()\n",
        "            boxplot_buffer.seek(0)\n",
        "            outputs[\"boxplot\"] = boxplot_buffer\n",
        "            conclusions.append(\"Boxplot generado correctamente.\")\n",
        "\n",
        "        # --- Mapa de Correlaciones ---\n",
        "        if \"heatmap\" in selected_columns and len(selected_columns[\"heatmap\"]) >= 2:\n",
        "            corr_matrix = dataframe[selected_columns[\"heatmap\"]].corr()\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
        "            plt.title(\"Mapa de Correlaciones\")\n",
        "            heatmap_buffer = BytesIO()\n",
        "            plt.savefig(heatmap_buffer, format=\"png\")\n",
        "            plt.close()\n",
        "            heatmap_buffer.seek(0)\n",
        "            outputs[\"heatmap\"] = heatmap_buffer\n",
        "            conclusions.append(\"Mapa de correlaciones generado correctamente.\")\n",
        "        else:\n",
        "            conclusions.append(\n",
        "                \"Nota: No se pudo generar el mapa de correlaciones porque se necesitan al menos 2 columnas.\"\n",
        "            )\n",
        "\n",
        "        # --- Histograma ---\n",
        "        if \"histogram\" in selected_columns and selected_columns[\"histogram\"]:\n",
        "            for col in selected_columns[\"histogram\"]:\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                sns.histplot(dataframe[col].dropna(), bins=20, kde=False, color=\"skyblue\")\n",
        "                plt.title(f\"Histograma de {col}\")\n",
        "                plt.xlabel(\"Valores\")\n",
        "                plt.ylabel(\"Frecuencia\")\n",
        "                hist_buffer = BytesIO()\n",
        "                plt.savefig(hist_buffer, format=\"png\")\n",
        "                plt.close()\n",
        "                hist_buffer.seek(0)\n",
        "                outputs[\"histograms\"].append(hist_buffer)\n",
        "                conclusions.append(f\"Histograma generado para la columna '{col}'.\")\n",
        "\n",
        "        # --- Gráfico de Densidad (KDE) ---\n",
        "        if \"density\" in selected_columns and selected_columns[\"density\"]:\n",
        "            for col in selected_columns[\"density\"]:\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                sns.kdeplot(data=dataframe[col].dropna(), fill=True, color=\"skyblue\")\n",
        "                plt.title(f\"Densidad de {col}\")\n",
        "                plt.xlabel(\"Valores\")\n",
        "                plt.ylabel(\"Densidad\")\n",
        "                density_buffer = BytesIO()\n",
        "                plt.savefig(density_buffer, format=\"png\")\n",
        "                plt.close()\n",
        "                density_buffer.seek(0)\n",
        "                outputs[\"density\"].append(density_buffer)\n",
        "                conclusions.append(f\"Gráfico de densidad generado para la columna '{col}'.\")\n",
        "\n",
        "        # --- Conclusiones sobre Curtosis ---\n",
        "        if \"boxplot\" in selected_columns and selected_columns[\"boxplot\"]:\n",
        "            for col in selected_columns[\"boxplot\"]:\n",
        "                curtosis = dataframe[col].kurt()\n",
        "                if curtosis > 3:\n",
        "                    conclusions.append(\n",
        "                        f\"La columna '{col}' tiene una curtosis alta (leptocúrtica), lo que indica colas más pesadas.\"\n",
        "                    )\n",
        "                elif curtosis < 3:\n",
        "                    conclusions.append(\n",
        "                        f\"La columna '{col}' tiene una curtosis baja (platicúrtica), lo que indica colas más ligeras.\"\n",
        "                    )\n",
        "                else:\n",
        "                    conclusions.append(\n",
        "                        f\"La columna '{col}' tiene una curtosis cercana a 3 (mesocúrtica), lo que indica una distribución normal.\"\n",
        "                    )\n",
        "\n",
        "        outputs[\"conclusions\"] = conclusions\n",
        "        return \"Gráficos generados correctamente.\", outputs[\"boxplot\"], outputs[\"heatmap\"], outputs[\"histograms\"], outputs[\"density\"], \"\\n\".join(conclusions)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error al generar gráficos: {str(e)}\", None, None, None, None, None\n",
        "\n",
        "# --- Exportar a Excel ---\n",
        "def export_to_excel(file_name=\"analisis.xlsx\"):\n",
        "    \"\"\"Exporta los resultados del análisis a un archivo Excel con múltiples hojas.\"\"\"\n",
        "    global dataframe\n",
        "    if dataframe is None:\n",
        "        return \"Error: No hay datos cargados para exportar.\"\n",
        "\n",
        "    try:\n",
        "        with pd.ExcelWriter(file_name, engine=\"openpyxl\") as writer:\n",
        "            # Datos originales\n",
        "            dataframe.to_excel(writer, sheet_name=\"Datos Originales\", index=False)\n",
        "\n",
        "            # Resumen estadístico\n",
        "            stats = dataframe.describe()\n",
        "            stats.to_excel(writer, sheet_name=\"Resumen Estadístico\")\n",
        "\n",
        "        return f\"Archivo Excel exportado con éxito: {file_name}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error al exportar a Excel: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "lFjl6OZrvmak"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# --- Interfaz de usuario ---\n",
        "with gr.Blocks() as interface:\n",
        "    # Encabezado de la aplicación\n",
        "    gr.Markdown(\"## Aplicación Interactiva para Procesamiento y Análisis de Datos\")\n",
        "    gr.Markdown(\n",
        "        \"### Desarrollado por Jorge Alfaro\\n\"\n",
        "        \"Esta herramienta fue creada para facilitar el procesamiento y análisis de datos de forma interactiva, \"\n",
        "        \"integrando técnicas de limpieza, transformación y análisis estadístico.\"\n",
        "    )\n",
        "\n",
        "    # Carga de archivo\n",
        "    gr.Markdown(\n",
        "        \"### Carga de archivo\\n\"\n",
        "        \"Permite cargar un archivo en formato CSV o Excel para su análisis. \"\n",
        "        \"El sistema genera un resumen indicando las columnas numéricas, categóricas y el número de filas totales.\"\n",
        "    )\n",
        "    file_input = gr.File(label=\"Cargar archivo\")\n",
        "    summary_output = gr.Textbox(label=\"Resumen de headers (Numéricos y Categóricos)\")\n",
        "    table_output = gr.DataFrame(label=\"Vista previa (hasta 100 filas)\")\n",
        "    file_input.change(process_file, inputs=[file_input], outputs=[summary_output, table_output])\n",
        "\n",
        "    # Limpieza de valores mixtos\n",
        "    gr.Markdown(\n",
        "        \"### Limpieza de Valores Mixtos\\n\"\n",
        "        \"Los valores mixtos se producen cuando una columna numérica contiene datos no numéricos, dificultando el análisis. \"\n",
        "        \"Esta función elimina esos valores no numéricos para normalizar los datos.\"\n",
        "    )\n",
        "    remove_mixed_button = gr.Button(\"Eliminar valores mixtos\")\n",
        "    remove_mixed_result = gr.Textbox(label=\"Resultado de limpieza de valores mixtos\")\n",
        "    updated_summary_output = gr.Textbox(label=\"Resumen actualizado de headers\")\n",
        "    updated_table_output = gr.DataFrame(label=\"Datos después de limpiar valores mixtos\")\n",
        "    remove_mixed_button.click(\n",
        "        remove_mixed_data,\n",
        "        outputs=[remove_mixed_result, updated_summary_output, updated_table_output]\n",
        "    )\n",
        "\n",
        "    # Limpieza de datos nulos\n",
        "    gr.Markdown(\n",
        "        \"### Limpieza de Valores Nulos\\n\"\n",
        "        \"Los valores nulos son datos faltantes en las columnas. \"\n",
        "        \"Esta función permite elegir entre reemplazarlos con 0, la media, la mediana, o eliminar las filas completas.\"\n",
        "    )\n",
        "    null_handling_options = gr.Dropdown(\n",
        "        choices=[\"Dejar los nulos o vacíos con valor 0\", \"Borrar la fila completa\", \"Colocar el promedio\", \"Colocar la mediana\"],\n",
        "        label=\"Selecciona una acción para los valores nulos\"\n",
        "    )\n",
        "    clean_button = gr.Button(\"Aplicar limpieza\")\n",
        "    clean_result = gr.Textbox(label=\"Resultado de limpieza\")\n",
        "    clean_table = gr.DataFrame(label=\"Datos después de la limpieza\")\n",
        "    clean_button.click(handle_nulls, inputs=[null_handling_options], outputs=[clean_result, clean_table])\n",
        "\n",
        "    # Selección de headers y transformación\n",
        "    gr.Markdown(\n",
        "        \"### Selección de Headers y Transformaciones\\n\"\n",
        "        \"Permite seleccionar una columna numérica para realizar transformaciones como normalización (Min-Max) o estandarización (Z-Score).\"\n",
        "    )\n",
        "    header_selector = gr.Textbox(label=\"Escribe el nombre del header (columna numérica)\", interactive=True)\n",
        "\n",
        "    # Normalización y estandarización\n",
        "    gr.Markdown(\n",
        "        \"### Normalización y Estandarización\\n\"\n",
        "        \"#### Normalización (Min-Max):\\n\"\n",
        "        \"- Escala los valores entre 0 y 1.\\n\"\n",
        "        \"- Fórmula: `(valor - mínimo) / (máximo - mínimo)`.\\n\\n\"\n",
        "        \"#### Estandarización (Z-Score):\\n\"\n",
        "        \"- Ajusta los valores para que tengan una media de 0 y una desviación estándar de 1.\\n\"\n",
        "        \"- Fórmula: `(valor - media) / desviación estándar`.\"\n",
        "    )\n",
        "    method_selector = gr.Dropdown(choices=[\"Min-Max\", \"Z-Score\"], label=\"Selecciona el método de transformación\")\n",
        "    normalize_button = gr.Button(\"Aplicar transformación\")\n",
        "    normalize_result = gr.Textbox(label=\"Resultado de la transformación\")\n",
        "    normalize_table = gr.DataFrame(label=\"Datos después de transformación\")\n",
        "    normalize_button.click(\n",
        "        normalize_or_standardize,\n",
        "        inputs=[header_selector, method_selector],\n",
        "        outputs=[normalize_result, normalize_table]\n",
        "    )\n",
        "\n",
        "    # Campo para seleccionar columnas para gráficos y análisis estadístico\n",
        "    gr.Markdown(\n",
        "        \"### Generación de Gráficos y Conclusiones\\n\"\n",
        "        \"Selecciona las columnas específicas para generar los diferentes gráficos. \"\n",
        "        \"El sistema generará las conclusiones con base en la curtosis y otros análisis estadísticos.\\n\"\n",
        "        \"- **Boxplot**: Admite 1 o más columnas.\\n\"\n",
        "        \"- **Mapa de Correlaciones**: Requiere 2 o más columnas.\\n\"\n",
        "        \"- **Histograma y Densidad**: Requieren 1 columna.\"\n",
        "    )\n",
        "    boxplot_input = gr.Textbox(label=\"Columnas para Boxplot (separadas por comas)\")\n",
        "    heatmap_input = gr.Textbox(label=\"Columnas para Mapa de Correlaciones (2 o más columnas)\")\n",
        "    histogram_input = gr.Textbox(label=\"Columnas para Histograma (1 columna)\")\n",
        "    density_input = gr.Textbox(label=\"Columnas para Densidad (1 columna)\")\n",
        "    generate_graphs_button = gr.Button(\"Generar Gráficos\")\n",
        "    graphs_boxplot = gr.Image(label=\"Boxplot de Outliers\")\n",
        "    graphs_correlation = gr.Image(label=\"Mapa de Correlaciones\")\n",
        "    graphs_histograms = gr.Gallery(label=\"Histogramas\")\n",
        "    graphs_density = gr.Gallery(label=\"Gráficos de Densidad\")\n",
        "    conclusions_output = gr.Textbox(label=\"Conclusiones Generales\")\n",
        "    generate_graphs_button.click(\n",
        "        generate_graphs_and_conclusions,\n",
        "        inputs=[boxplot_input, heatmap_input, histogram_input, density_input],\n",
        "        outputs=[graphs_boxplot, graphs_correlation, graphs_histograms, graphs_density, conclusions_output]\n",
        "    )\n",
        "\n",
        "    # Generar Informe\n",
        "    gr.Markdown(\n",
        "        \"### Generación de Informes\\n\"\n",
        "        \"Genera un archivo de texto con un resumen de las decisiones tomadas y un análisis estadístico de los datos cargados.\"\n",
        "    )\n",
        "    generate_log_button = gr.Button(\"Generar Informe\")\n",
        "    log_file = gr.File(label=\"Descargar Informe\")\n",
        "    generate_log_button.click(\n",
        "        lambda: \"informe_log.txt\", outputs=log_file\n",
        "    )\n",
        "\n",
        "    # Exportar a Excel\n",
        "    gr.Markdown(\n",
        "        \"### Exportar a Excel\\n\"\n",
        "        \"Exporta los datos originales, análisis estadístico, y otros resultados en un archivo Excel con múltiples hojas.\"\n",
        "    )\n",
        "    export_button = gr.Button(\"Exportar a Excel\")\n",
        "    excel_file = gr.File(label=\"Descargar Excel\")\n",
        "    export_button.click(\n",
        "        lambda: \"analisis.xlsx\", outputs=excel_file\n",
        "    )\n",
        "\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "Sps85ngC6IYJ",
        "outputId": "1a4f0520-0b51-4024-e88e-168733873848"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:999: UserWarning: Expected 1 arguments for function <function generate_graphs_and_conclusions at 0x7ac2098cad40>, received 4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:1007: UserWarning: Expected maximum 1 arguments for function <function generate_graphs_and_conclusions at 0x7ac2098cad40>, received 4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2df0ae05a392da1cfb.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2df0ae05a392da1cfb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}